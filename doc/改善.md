参考 ./ref 三个项目（MoneyPrinterTurbo、ShortGPT、ViMax），结合当前 DeepSeek→EdgeTTS→Wavespeed→MoviePy 流程，可优先考虑的改进思路：


MoneyPrinterTurbo 启发
- 增加 Web/UI 与 API 双入口：参考其 MVC 结构，将 ad-aka 主流程包成服务层 + 控制器，便于后续接 Gradio/Streamlit 或 FastAPI。
- 素材源扩充与参数化：集成 Pexels/无版权素材作为视频/图片备选，减少 I2V 成本；支持批量生成、可配置片段时长/分辨率/纵横比。
- 字幕与配乐样式化：增加字体、位置、描边、颜色、音量等可配置项，生成阶段写入 checkpoint 供断点续传，提升用户可控度。


ShortGPT 启发
- “编辑语言”中间表示：引入简单的 JSON/DSL 描述（镜头顺序、文本、BGM、转场），先生成脚本再渲染，可插入人工或自动审阅。
- 状态持久化：TinyDB/本地 JSON 记录任务变量（脚本版本、素材路径、失败重试次数），为断点续传提供更细粒度的信息。


ViMax 启发: 人物一致性、分镜
- 角色/场景一致性：生成分镜时提取角色/场景特征，前后镜头共享 reference prompt；首帧可生成多张图，借助 VLM/评分模型挑选一致性最好的一张再进 I2V。
- 多代理编排：拆成“剧本理解/镜头计划/素材规划/一致性校验/生成执行”子模块，中心调度负责资源与重试，便于并行优化（同场景镜头并发）。
- 长文/小说改编模式：增加 Novel2Video 流程，长文本→分章节→分镜，自动压缩关键信息并维持人物线索。
- 连贯性缓存：建立“资产索引”（关键帧、人物 embedding、镜头元数据），下个镜头生成 prompt 时检索最近镜头，提升时空连贯。


可落地的优先级建议 
1) 在分镜 JSON 增加一致性字段（角色描述、上一镜头引用）和可视化参数（字幕样式、BGM 音量），保持与断点续传兼容。  
2) 视资源情况引入 VLM 评分或低成本 embedding，对多张首帧自动择优，逐步提升镜头连贯性。
