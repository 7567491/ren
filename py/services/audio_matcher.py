#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘æ™ºèƒ½åŒ¹é…å¼•æ“ - åŸºäºæ—ç™½éŸ³é¢‘ç‰¹å¾åŒ¹é…èƒŒæ™¯éŸ³ä¹
æ”¯æŒ5ç»´åº¦åˆ†æï¼šèŠ‚å¥ã€èƒ½é‡ã€æƒ…ç»ªã€é¢‘è°±ã€æ—¶é•¿
"""

import json
import librosa
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from loguru import logger


class AudioMatcher:
    """éŸ³é¢‘æ™ºèƒ½åŒ¹é…å™¨"""

    def __init__(self, music_features_cache: Optional[str] = None):
        """
        åˆå§‹åŒ–åŒ¹é…å™¨

        Args:
            music_features_cache: éŸ³ä¹ç‰¹å¾ç¼“å­˜æ–‡ä»¶è·¯å¾„
        """
        self.music_features = {}
        if music_features_cache and Path(music_features_cache).exists():
            with open(music_features_cache, 'r', encoding='utf-8') as f:
                self.music_features = json.load(f)

    # ==================== æ—ç™½éŸ³é¢‘åˆ†æ ====================

    def analyze_narration_audio(self, audio_files: List[Path]) -> Dict:
        """
        åˆ†ææ‰€æœ‰æ—ç™½éŸ³é¢‘çš„ç»¼åˆç‰¹å¾

        Args:
            audio_files: æ—ç™½éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨ [shot_1_audio.mp3, shot_2_audio.mp3, ...]

        Returns:
            ç»¼åˆç‰¹å¾å­—å…¸
        """
        logger.info(f"ğŸ¤ åˆ†æ {len(audio_files)} ä¸ªæ—ç™½éŸ³é¢‘...")

        all_features = []
        total_duration = 0.0

        for audio_file in audio_files:
            if not audio_file.exists():
                logger.warning(f"âš ï¸  éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
                continue

            features = self._extract_narration_features(audio_file)
            all_features.append(features)
            total_duration += features['duration']

        if not all_features:
            logger.error("âŒ æœªæˆåŠŸåˆ†æä»»ä½•æ—ç™½éŸ³é¢‘")
            return {}

        # è®¡ç®—ç»¼åˆç‰¹å¾ï¼ˆåŠ æƒå¹³å‡ï¼‰
        combined = self._combine_narration_features(all_features, total_duration)

        logger.success(f"âœ… æ—ç™½åˆ†æå®Œæˆ: æ€»æ—¶é•¿ {total_duration:.1f}s, å¹³å‡è¯­é€Ÿ {combined['avg_speech_rate']:.1f} syllables/s")
        return combined

    def _extract_narration_features(self, audio_file: Path) -> Dict:
        """
        æå–å•ä¸ªæ—ç™½éŸ³é¢‘çš„ç‰¹å¾

        Returns:
            {
                'duration': æ—¶é•¿,
                'rms_energy': RMSèƒ½é‡,
                'zero_crossing_rate': è¿‡é›¶ç‡ï¼ˆè¯­é€ŸæŒ‡æ ‡ï¼‰,
                'spectral_centroid': é¢‘è°±è´¨å¿ƒï¼ˆéŸ³è°ƒäº®åº¦ï¼‰,
                'pitch_variance': éŸ³è°ƒæ–¹å·®ï¼ˆæƒ…ç»ªæ³¢åŠ¨ï¼‰,
                'speech_rate': ä¼°ç®—è¯­é€Ÿ
            }
        """
        try:
            # åŠ è½½éŸ³é¢‘
            y, sr = librosa.load(str(audio_file), sr=None)

            # 1. åŸºç¡€ç‰¹å¾
            duration = librosa.get_duration(y=y, sr=sr)

            # 2. èƒ½é‡ç‰¹å¾ï¼ˆRMSï¼‰
            rms = librosa.feature.rms(y=y)[0]
            rms_mean = float(np.mean(rms))
            rms_std = float(np.std(rms))

            # 3. è¿‡é›¶ç‡ï¼ˆZero Crossing Rate - åæ˜ è¯­é€Ÿï¼‰
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            zcr_mean = float(np.mean(zcr))

            # 4. é¢‘è°±è´¨å¿ƒï¼ˆSpectral Centroid - éŸ³è°ƒäº®åº¦ï¼‰
            spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            sc_mean = float(np.mean(spectral_centroid))

            # 5. éŸ³è°ƒä¼°ç®—ï¼ˆPitchï¼‰
            pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
            pitch_values = []
            for t in range(pitches.shape[1]):
                index = magnitudes[:, t].argmax()
                pitch = pitches[index, t]
                if pitch > 0:  # è¿‡æ»¤é™éŸ³å¸§
                    pitch_values.append(pitch)

            pitch_variance = float(np.var(pitch_values)) if pitch_values else 0.0

            # 6. ä¼°ç®—è¯­é€Ÿï¼ˆåŸºäºonsetæ£€æµ‹ï¼‰
            onset_env = librosa.onset.onset_strength(y=y, sr=sr)
            onset_frames = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)
            speech_rate = len(onset_frames) / duration if duration > 0 else 0.0

            return {
                'duration': float(duration),
                'rms_energy': rms_mean,
                'rms_std': rms_std,
                'zero_crossing_rate': zcr_mean,
                'spectral_centroid': sc_mean,
                'pitch_variance': pitch_variance,
                'speech_rate': speech_rate,  # onsets per second (è¿‘ä¼¼éŸ³èŠ‚/ç§’)
            }

        except Exception as e:
            logger.error(f"âŒ åˆ†æéŸ³é¢‘å¤±è´¥ {audio_file.name}: {e}")
            return {'duration': 0.0}

    def _combine_narration_features(self, features_list: List[Dict], total_duration: float) -> Dict:
        """
        åˆå¹¶å¤šä¸ªæ—ç™½çš„ç‰¹å¾ï¼ˆæŒ‰æ—¶é•¿åŠ æƒå¹³å‡ï¼‰
        """
        if not features_list:
            return {}

        # æŒ‰æ—¶é•¿åŠ æƒ
        weights = np.array([f['duration'] for f in features_list])
        weights = weights / weights.sum()

        combined = {
            'total_duration': total_duration,
            'avg_rms_energy': float(np.average([f['rms_energy'] for f in features_list], weights=weights)),
            'avg_rms_std': float(np.average([f['rms_std'] for f in features_list], weights=weights)),
            'avg_zcr': float(np.average([f['zero_crossing_rate'] for f in features_list], weights=weights)),
            'avg_spectral_centroid': float(np.average([f['spectral_centroid'] for f in features_list], weights=weights)),
            'avg_pitch_variance': float(np.average([f['pitch_variance'] for f in features_list], weights=weights)),
            'avg_speech_rate': float(np.average([f['speech_rate'] for f in features_list], weights=weights)),
        }

        return combined

    # ==================== éŸ³ä¹åº“ç‰¹å¾æå– ====================

    def analyze_music_library(self, music_dir: Path, output_cache: Optional[str] = None) -> Dict:
        """
        åˆ†æéŸ³ä¹åº“ï¼Œæå–æ‰€æœ‰éŸ³ä¹çš„ç‰¹å¾

        Args:
            music_dir: éŸ³ä¹ç›®å½•
            output_cache: è¾“å‡ºç¼“å­˜æ–‡ä»¶è·¯å¾„

        Returns:
            éŸ³ä¹ç‰¹å¾å­—å…¸ {filename: features}
        """
        logger.info(f"ğŸµ å¼€å§‹åˆ†æéŸ³ä¹åº“: {music_dir}")

        music_files = list(music_dir.glob('*.mp3')) + list(music_dir.glob('*.wav')) + list(music_dir.glob('*.m4a'))

        if not music_files:
            logger.error(f"âŒ æœªæ‰¾åˆ°éŸ³ä¹æ–‡ä»¶: {music_dir}")
            return {}

        features_dict = {}

        for i, music_file in enumerate(music_files, 1):
            logger.info(f"  [{i}/{len(music_files)}] åˆ†æ: {music_file.name}")
            features = self._extract_music_features(music_file)
            if features:
                features_dict[music_file.name] = features

        # ä¿å­˜ç¼“å­˜
        if output_cache:
            cache_path = Path(output_cache)
            cache_path.parent.mkdir(parents=True, exist_ok=True)
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(features_dict, f, indent=2, ensure_ascii=False)
            logger.success(f"âœ… éŸ³ä¹ç‰¹å¾ç¼“å­˜å·²ä¿å­˜: {cache_path}")

        self.music_features = features_dict
        return features_dict

    def _extract_music_features(self, music_file: Path) -> Optional[Dict]:
        """
        æå–å•ä¸ªéŸ³ä¹æ–‡ä»¶çš„ç‰¹å¾

        Returns:
            {
                'duration': æ—¶é•¿,
                'bpm': èŠ‚å¥,
                'rms_energy': å¹³å‡èƒ½é‡,
                'spectral_centroid': é¢‘è°±è´¨å¿ƒ,
                'dynamic_range': åŠ¨æ€èŒƒå›´,
                'beat_strength': èŠ‚æ‹å¼ºåº¦
            }
        """
        try:
            # åŠ è½½éŸ³é¢‘ï¼ˆé™åˆ¶æ—¶é•¿ä»¥åŠ é€Ÿåˆ†æï¼‰
            y, sr = librosa.load(str(music_file), sr=22050, duration=60)  # åªåˆ†æå‰60ç§’

            # 1. æ—¶é•¿
            duration = float(librosa.get_duration(y=y, sr=sr))

            # 2. BPMï¼ˆèŠ‚å¥ï¼‰
            tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
            bpm = float(tempo)

            # 3. RMSèƒ½é‡
            rms = librosa.feature.rms(y=y)[0]
            rms_mean = float(np.mean(rms))

            # 4. é¢‘è°±è´¨å¿ƒ
            spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            sc_mean = float(np.mean(spectral_centroid))

            # 5. åŠ¨æ€èŒƒå›´ï¼ˆæœ€å¤§èƒ½é‡ / æœ€å°èƒ½é‡ï¼‰
            rms_max = float(np.max(rms))
            rms_min = float(np.min(rms[rms > 0])) if np.any(rms > 0) else 0.001
            dynamic_range = rms_max / rms_min

            # 6. èŠ‚æ‹å¼ºåº¦
            onset_env = librosa.onset.onset_strength(y=y, sr=sr)
            beat_strength = float(np.mean(onset_env))

            return {
                'duration': duration,
                'bpm': bpm,
                'rms_energy': rms_mean,
                'spectral_centroid': sc_mean,
                'dynamic_range': dynamic_range,
                'beat_strength': beat_strength,
            }

        except Exception as e:
            logger.error(f"âŒ åˆ†æéŸ³ä¹å¤±è´¥ {music_file.name}: {e}")
            return None

    # ==================== æ™ºèƒ½åŒ¹é…ç®—æ³• ====================

    def calculate_match_score(
        self,
        narration_features: Dict,
        music_name: str
    ) -> Tuple[float, Dict]:
        """
        è®¡ç®—æ—ç™½ä¸éŸ³ä¹çš„åŒ¹é…åˆ†æ•°ï¼ˆ0-1ï¼‰

        Args:
            narration_features: æ—ç™½ç»¼åˆç‰¹å¾
            music_name: éŸ³ä¹æ–‡ä»¶å

        Returns:
            (æ€»åˆ†, å„ç»´åº¦åˆ†æ•°è¯¦æƒ…)
        """
        if music_name not in self.music_features:
            return 0.0, {}

        music_feat = self.music_features[music_name]

        # 1. èŠ‚å¥åŒ¹é…ï¼ˆSpeech Rate vs BPMï¼‰
        # è¯­é€Ÿè½¬BPMï¼šspeech_rate * 60 (å‡è®¾1 onset â‰ˆ 1æ‹)
        narration_bpm = narration_features['avg_speech_rate'] * 60
        music_bpm = music_feat['bpm']

        # è®¡ç®—BPMæ¯”ä¾‹ï¼ˆç†æƒ³æ˜¯1:1æˆ–1:2ï¼‰
        bpm_ratio = narration_bpm / music_bpm if music_bpm > 0 else 0
        if bpm_ratio > 1:
            bpm_ratio = 1 / bpm_ratio

        # å…è®¸1:1æˆ–1:2çš„å…³ç³»
        rhythm_score = max(bpm_ratio, bpm_ratio * 2 if bpm_ratio * 2 <= 1 else 0)
        rhythm_score = min(rhythm_score, 1.0)

        # 2. èƒ½é‡åŒ¹é…ï¼ˆRMSï¼‰
        narration_energy = narration_features['avg_rms_energy']
        music_energy = music_feat['rms_energy']

        # å½’ä¸€åŒ–èƒ½é‡å·®å¼‚ï¼ˆæœŸæœ›å·®å¼‚å°äº50%ï¼‰
        energy_diff = abs(narration_energy - music_energy) / max(narration_energy, music_energy, 0.01)
        energy_score = max(0, 1 - energy_diff)

        # 3. åŠ¨æ€èŒƒå›´åŒ¹é…ï¼ˆæƒ…ç»ªæ³¢åŠ¨ï¼‰
        narration_dynamics = narration_features['avg_rms_std']
        music_dynamics = music_feat['dynamic_range']

        # å½’ä¸€åŒ–åè®¡ç®—ç›¸ä¼¼åº¦
        dynamics_score = 1 - min(abs(narration_dynamics - music_dynamics / 10) / 0.5, 1.0)

        # 4. é¢‘è°±äº’è¡¥æ€§ï¼ˆé¿å…å†²çªï¼‰
        # äººå£°ä¸»è¦åœ¨ 300-3000Hzï¼ŒéŸ³ä¹æœ€å¥½åä½é¢‘æˆ–é«˜é¢‘
        narration_sc = narration_features['avg_spectral_centroid']
        music_sc = music_feat['spectral_centroid']

        # å¦‚æœéŸ³ä¹é¢‘è°±è´¨å¿ƒè¿œç¦»äººå£°èŒƒå›´ï¼Œå¾—åˆ†æ›´é«˜
        spectral_diff = abs(narration_sc - music_sc)
        spectral_score = min(spectral_diff / 2000, 1.0)  # å·®å¼‚è¶Šå¤§è¶Šå¥½

        # 5. æ—¶é•¿é€‚é…ï¼ˆå‡å°‘å¾ªç¯æ¬¡æ•°ï¼‰
        total_duration = narration_features['total_duration']
        music_duration = music_feat['duration']

        # è®¡ç®—éœ€è¦å¾ªç¯çš„æ¬¡æ•°
        loops_needed = total_duration / music_duration if music_duration > 0 else 10
        duration_score = 1 / (1 + abs(loops_needed - 1))  # æ¥è¿‘1æ¬¡å¾ªç¯å¾—åˆ†æœ€é«˜

        # åŠ æƒè®¡ç®—æ€»åˆ†
        weights = {
            'rhythm': 0.40,      # èŠ‚å¥æœ€é‡è¦
            'energy': 0.214,     # èƒ½é‡æ¬¡ä¹‹
            'dynamics': 0.171,   # åŠ¨æ€èŒƒå›´
            'spectral': 0.129,   # é¢‘è°±äº’è¡¥
            'duration': 0.086,   # æ—¶é•¿é€‚é…
        }

        total_score = (
            rhythm_score * weights['rhythm'] +
            energy_score * weights['energy'] +
            dynamics_score * weights['dynamics'] +
            spectral_score * weights['spectral'] +
            duration_score * weights['duration']
        )

        details = {
            'rhythm_score': round(rhythm_score, 3),
            'energy_score': round(energy_score, 3),
            'dynamics_score': round(dynamics_score, 3),
            'spectral_score': round(spectral_score, 3),
            'duration_score': round(duration_score, 3),
            'total_score': round(total_score, 3),
            'narration_bpm_est': round(narration_bpm, 1),
            'music_bpm': round(music_bpm, 1),
            'loops_needed': round(loops_needed, 2),
        }

        return total_score, details

    def rank_music_candidates(
        self,
        narration_features: Dict,
        top_k: int = 5
    ) -> List[Tuple[str, float, Dict]]:
        """
        å¯¹æ‰€æœ‰éŸ³ä¹è¿›è¡Œæ’åºï¼Œè¿”å›Top-Kå€™é€‰

        Returns:
            [(music_name, score, details), ...]
        """
        if not self.music_features:
            logger.error("âŒ éŸ³ä¹ç‰¹å¾åº“ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œé¢„å¤„ç†")
            return []

        candidates = []

        for music_name in self.music_features.keys():
            score, details = self.calculate_match_score(narration_features, music_name)
            candidates.append((music_name, score, details))

        # æŒ‰åˆ†æ•°é™åºæ’åº
        candidates.sort(key=lambda x: x[1], reverse=True)

        # è¿”å›Top-K
        return candidates[:top_k]

    def format_candidates_for_llm(
        self,
        candidates: List[Tuple[str, float, Dict]]
    ) -> str:
        """
        æ ¼å¼åŒ–å€™é€‰éŸ³ä¹åˆ—è¡¨ï¼Œç”¨äºDeepSeekæ¨ç†
        """
        lines = []
        for i, (music_name, score, details) in enumerate(candidates, 1):
            lines.append(f"{i}. {music_name}")
            lines.append(f"   æ€»åˆ†: {score:.2f}")
            lines.append(f"   èŠ‚å¥åŒ¹é…: {details['rhythm_score']:.2f} (æ—ç™½â‰ˆ{details['narration_bpm_est']}BPM vs éŸ³ä¹{details['music_bpm']}BPM)")
            lines.append(f"   èƒ½é‡åŒ¹é…: {details['energy_score']:.2f}")
            lines.append(f"   åŠ¨æ€èŒƒå›´: {details['dynamics_score']:.2f}")
            lines.append(f"   é¢‘è°±äº’è¡¥: {details['spectral_score']:.2f}")
            lines.append(f"   æ—¶é•¿é€‚é…: {details['duration_score']:.2f} (éœ€å¾ªç¯{details['loops_needed']}æ¬¡)")
            lines.append("")

        return "\n".join(lines)


# ==================== ä¾¿æ·å‡½æ•° ====================

def preprocess_music_library(music_dir: str, output_cache: str = "resource/music_features.json"):
    """
    é¢„å¤„ç†éŸ³ä¹åº“ï¼ˆä¸€æ¬¡æ€§æ“ä½œï¼‰

    Usage:
        python -c "from py.services.audio_matcher import preprocess_music_library; preprocess_music_library('./resource/songs')"
    """
    matcher = AudioMatcher()
    features = matcher.analyze_music_library(Path(music_dir), output_cache)

    logger.success(f"âœ… é¢„å¤„ç†å®Œæˆï¼å…±åˆ†æ {len(features)} é¦–éŸ³ä¹")
    logger.info(f"ğŸ’¾ ç‰¹å¾ç¼“å­˜: {output_cache}")

    return features


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import sys

    if len(sys.argv) > 1:
        music_dir = sys.argv[1]
        output_cache = sys.argv[2] if len(sys.argv) > 2 else "resource/music_features.json"
        preprocess_music_library(music_dir, output_cache)
    else:
        logger.info("ç”¨æ³•: python py/services/audio_matcher.py <music_dir> [output_cache]")
        logger.info("ç¤ºä¾‹: python py/services/audio_matcher.py ./resource/songs ./resource/music_features.json")
