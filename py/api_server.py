"""
AI è§†é¢‘ç”Ÿæˆ REST API æœåŠ¡
æä¾› Web API æ¥å£ï¼Œç®¡ç†ä»»åŠ¡é˜Ÿåˆ—å’Œå­è¿›ç¨‹æ‰§è¡Œ
"""
import json
import os
import sys
import shutil
import yaml
import asyncio
import subprocess
from pathlib import Path
from typing import Optional, List
from datetime import datetime
from urllib.parse import urlparse

import requests
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, ConfigDict

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from py.services.task_manager import TaskManager
from py.services.eta_estimator import ETAEstimator
from py.services import character_library

# ==================== FastAPI åº”ç”¨åˆå§‹åŒ– ====================
app = FastAPI(
    title="AI Video Generation API",
    description="AI æ•…äº‹åŒ–è§†é¢‘ç”Ÿæˆç³»ç»Ÿ REST API",
    version="1.0.0"
)

# CORS é…ç½®ï¼ˆå…è®¸å‰ç«¯è°ƒç”¨ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”é™åˆ¶æ¥æº
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== å…¨å±€å˜é‡ ====================
TEMP_DIR = "temp"
OUTPUT_DIR = "output"
PUBLIC_EXPORT_DIR = Path("/mnt/www")
PUBLIC_EXPORT_URL = "https://s.linapp.fun"
task_manager = TaskManager(storage_dir=TEMP_DIR)
eta_estimator = ETAEstimator(stats_file=Path(TEMP_DIR) / "eta_stats.json")
eta_bootstrap_done = False

# å¹¶å‘é™åˆ¶ï¼ˆä»é…ç½®è¯»å–ï¼‰
MAX_CONCURRENT_TASKS = 1
PROGRESS_POLL_INTERVAL = 1  # seconds between checkpoint inspections
running_tasks = {}  # {job_id: subprocess}
WAVESPEED_BALANCE_URL = "https://api.wavespeed.ai/api/v3/balance"
CHARACTER_IMAGE_TIMEOUT = 10

# ==================== é¢„è®¾æ˜ å°„é…ç½® ====================
# é¢„è®¾åç§°åˆ°é£æ ¼ç¼–å·çš„æ˜ å°„ï¼ˆå¯¹åº” ad-back.py ä¸­çš„ STYLE_NUMBER_MAPï¼‰
PRESET_TO_STYLE_NUMBER = {
    'å¡é€š': 1,        # cartoon_adventure
    'æ—¶å°š': 2,        # luxury_fashion
    'ä»™ä¾ ': 3,        # ink_xianxia
    '3D': 4,          # realistic_3d
    'ç”µå½±': 5,        # cinematic
    'ç§‘æŠ€': 6,        # technology
    'èµ›åšæœ‹å…‹': 7,    # cyberpunk
    'å¤ªç©º': 8,        # space_exploration
    'æˆ·å¤–': 9,        # outdoor_adventure
    'é­”æ³•': 10,       # magical_fantasy
    # è‹±æ–‡åˆ«å
    'cartoon': 1,
    'fashion': 2,
    'xianxia': 3,
    'realistic': 4,
    'cinematic': 5,
    'technology': 6,
    'cyberpunk': 7,
    'space': 8,
    'outdoor': 9,
    'magic': 10,
}


def set_temp_dir(temp_dir: str):
    """è®¾ç½®ä¸´æ—¶ç›®å½•ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global task_manager, TEMP_DIR, eta_estimator, eta_bootstrap_done
    TEMP_DIR = temp_dir
    task_manager = TaskManager(storage_dir=temp_dir)
    eta_estimator = ETAEstimator(stats_file=Path(temp_dir) / "eta_stats.json")
    eta_bootstrap_done = False


def generate_config_from_preset(
    topic: Optional[str],
    preset_name: Optional[str],
    num_shots: int,
    shot_duration: int,
    resolution: str,
    llm_provider: int,
    image_model: int,
    video_model: int,
    voice: int,
    concurrent_workers: int,
    job_id: str,
    character_enabled: bool = False,
    character_image_url: Optional[str] = None,
    character_description: Optional[str] = None,
    character_name: Optional[str] = None,
    logo_outro_enabled: Optional[bool] = True
) -> dict:
    """
    æ ¹æ®é¢„è®¾å‚æ•°ç”Ÿæˆå®Œæ•´é…ç½®

    Args:
        topic: è§†é¢‘ä¸»é¢˜
        preset_name: é¢„è®¾åç§°ï¼ˆå¦‚"ç§‘æŠ€"ã€"ä»™ä¾ "ç­‰ï¼‰
        num_shots: é•œå¤´æ•°
        shot_duration: æ¯é•œå¤´æ—¶é•¿
        resolution: åˆ†è¾¨ç‡
        llm_provider: LLMæä¾›å•†ï¼ˆä»…æ”¯æŒ 1=DeepSeekï¼‰
        image_model: å›¾åƒæ¨¡å‹ï¼ˆ1-6ï¼‰
        video_model: è§†é¢‘æ¨¡å‹ï¼ˆ1-5ï¼‰
        voice: éŸ³è‰²é€‰æ‹©ï¼ˆ1-13ï¼‰
        concurrent_workers: å¹¶å‘çº¿ç¨‹æ•°
        job_id: ä»»åŠ¡ ID
        logo_outro_enabled: æ˜¯å¦å¯ç”¨ç‰‡å°¾logoåŠ¨ç”»

    Returns:
        é…ç½®å­—å…¸

    Raises:
        ValueError: å¦‚æœé¢„è®¾åç§°æ— æ•ˆ
    """
    # é»˜è®¤é£æ ¼ç¼–å·
    style_num = 6  # é»˜è®¤ï¼šç§‘æŠ€

    # æ ¹æ®é¢„è®¾åç§°æŸ¥æ‰¾é£æ ¼ç¼–å·
    if preset_name:
        if preset_name in PRESET_TO_STYLE_NUMBER:
            style_num = PRESET_TO_STYLE_NUMBER[preset_name]
        else:
            # å°è¯•éƒ¨åˆ†åŒ¹é…
            for key, value in PRESET_TO_STYLE_NUMBER.items():
                if key in preset_name or preset_name in key:
                    style_num = value
                    break

    # æ„å»ºå®Œæ•´é…ç½®ï¼ˆå¯¹åº”user.yamlç»“æ„ï¼‰
    include_logo_outro = True if logo_outro_enabled is None else bool(logo_outro_enabled)

    config = {
        'topic': topic or f'AIè§†é¢‘-{job_id}',
        'style': style_num,
        'shot_count': num_shots,
        'shot_duration': shot_duration,
        'resolution': resolution,
        'llm': {
            'provider': llm_provider
        },
        'models': {
            'image': image_model,
            'video': video_model
        },
        'audio': {
            'voice': voice
        },
        'workflow': {
            'concurrent_workers': concurrent_workers
        }
    }

    if character_enabled:
        character_config = {
            'enabled': True,
            'description': (character_description or '').strip() or 'ä¸»è§’è§’è‰²'
        }
        cleaned_name = (character_name or '').strip()
        if cleaned_name:
            character_config['name'] = cleaned_name
        if character_image_url:
            character_config['character_image'] = character_image_url.strip()
        config['character'] = character_config
    else:
        config['character'] = {'enabled': False}

    config['logo'] = {
        'enabled': include_logo_outro
    }

    # éªŒè¯é…ç½®æœ‰æ•ˆæ€§
    validate_config(config)

    return config


def validate_config(config: dict) -> None:
    """
    éªŒè¯é…ç½®æœ‰æ•ˆæ€§

    Args:
        config: é…ç½®å­—å…¸

    Raises:
        ValueError: å¦‚æœé…ç½®æ— æ•ˆ
    """
    # éªŒè¯å¿…éœ€å­—æ®µ
    required_fields = ['topic', 'style', 'shot_count', 'shot_duration', 'resolution']
    for field in required_fields:
        if field not in config:
            raise ValueError(f"é…ç½®ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")

    # éªŒè¯é£æ ¼ç¼–å·
    style = config['style']
    if not isinstance(style, int):
        raise ValueError(f"é£æ ¼ç¼–å·å¿…é¡»æ˜¯æ•´æ•°ï¼Œå½“å‰: {type(style)}")

    if style < 1 or style > 10:
        raise ValueError(f"é£æ ¼ç¼–å· {style} æ— æ•ˆï¼Œæœ‰æ•ˆèŒƒå›´: 1-10")

    # éªŒè¯é•œå¤´æ•°
    shot_count = config['shot_count']
    if shot_count < 1 or shot_count > 10:
        raise ValueError(f"é•œå¤´æ•° {shot_count} æ— æ•ˆï¼Œæœ‰æ•ˆèŒƒå›´: 1-10")

    # éªŒè¯åˆ†è¾¨ç‡
    valid_resolutions = ['480p', '720p', '1080p']
    if config['resolution'] not in valid_resolutions:
        raise ValueError(f"åˆ†è¾¨ç‡ {config['resolution']} æ— æ•ˆï¼Œæœ‰æ•ˆå€¼: {valid_resolutions}")


# å…¼å®¹å†å²æµ‹è¯•æ¥å£
validate_config_params = validate_config


def validate_character_image_url(image_url: str) -> None:
    """ç¡®ä¿å‚è€ƒå›¾URLå¯è®¿é—®å¹¶è¿”å›å›¾ç‰‡ã€‚"""
    parsed = urlparse(image_url)
    if parsed.scheme not in ('http', 'https'):
        raise HTTPException(status_code=400, detail="å‚è€ƒå›¾URLå¿…é¡»ä»¥ http æˆ– https å¼€å¤´")

    response = None
    try:
        response = requests.get(image_url, timeout=CHARACTER_IMAGE_TIMEOUT, stream=True)
        response.raise_for_status()
    except requests.RequestException as exc:
        raise HTTPException(status_code=400, detail=f"æ— æ³•è®¿é—®å‚è€ƒå›¾: {exc}") from exc
    finally:
        if response is not None:
            try:
                response.close()
            except Exception:
                pass

    content_type = (response.headers.get('Content-Type') or '').lower()
    if 'image' not in content_type:
        raise HTTPException(status_code=400, detail="å‚è€ƒå›¾URLè¿”å›çš„ä¸æ˜¯å›¾ç‰‡èµ„æº")


def fetch_wavespeed_balance(api_key: str, timeout: int = 10) -> Optional[float]:
    """æŸ¥è¯¢ Wavespeed ä½™é¢ï¼ˆè¿”å›ç¾å…ƒï¼‰ï¼Œå¤±è´¥è¿”å› None"""
    if not api_key:
        return None

    try:
        response = requests.get(
            WAVESPEED_BALANCE_URL,
            headers={"Authorization": f"Bearer {api_key}"},
            timeout=timeout
        )
        response.raise_for_status()
        payload = response.json()

        if isinstance(payload, dict) and 'data' in payload and isinstance(payload['data'], dict):
            data = payload['data']
            balance = data.get('balance') or data.get('credit') or data.get('amount')
        else:
            balance = payload.get('balance') or payload.get('credit') or payload.get('amount')

        if balance is None:
            return None
        return float(balance)
    except requests.exceptions.RequestException:
        raise



# ==================== è¯·æ±‚æ¨¡å‹ ====================
class JobCreateRequest(BaseModel):
    """åˆ›å»ºä»»åŠ¡è¯·æ±‚"""
    model_config = ConfigDict(
        json_schema_extra={
            "example": {
                "topic": "ä¸€ä¸ªæŠ•èµ„é“¶è¡Œå®¢æˆ·ç»ç†ä½¿ç”¨Akamaiæ¨ç†äº‘",
                "preset_name": "ç§‘æŠ€",
                "num_shots": 5,
                "shot_duration": 5,
                "resolution": "720p",
                "llm_provider": 1,
                "image_model": 4,
                "video_model": 1,
                "voice": 6,
                "concurrent_workers": 6
            }
        }
    )

    # åŸºç¡€é…ç½®
    topic: Optional[str] = None
    preset_name: Optional[str] = None
    num_shots: Optional[int] = 5
    shot_duration: Optional[int] = 5
    resolution: Optional[str] = "720p"

    # æ¨¡å‹é€‰æ‹©
    llm_provider: Optional[int] = 1
    image_model: Optional[int] = 4
    video_model: Optional[int] = 1
    voice: Optional[int] = 6

    # å·¥ä½œæµé…ç½®
    concurrent_workers: Optional[int] = 6
    logo_outro_enabled: Optional[bool] = True

    # APIå¯†é’¥ï¼ˆå‰ç«¯ä¼ é€’ï¼‰
    wavespeed_api_key: Optional[str] = None

    # å‚è€ƒäººç‰©å›¾é…ç½®
    character_enabled: Optional[bool] = False
    character_image_url: Optional[str] = None
    character_description: Optional[str] = None
    character_name: Optional[str] = None

    # é«˜çº§æ¨¡å¼
    user_yaml: Optional[str] = None
    resume_id: Optional[str] = None
    no_auto_resume: Optional[bool] = False


class JobResponse(BaseModel):
    """ä»»åŠ¡å“åº”"""
    job_id: str
    status: str
    message: str = ""
    progress: float = 0.0
    result_path: Optional[str] = None
    created_at: str = ""
    eta_profile: Optional[dict] = None
    num_shots: Optional[int] = None


class LogResponse(BaseModel):
    """æ—¥å¿—å“åº”"""
    lines: List[str]
    total_lines: int = 0
    eof: bool = True


class BalanceRequest(BaseModel):
    """è´¦æˆ·ä½™é¢æŸ¥è¯¢è¯·æ±‚"""
    wavespeed_api_key: str


class BalanceResponse(BaseModel):
    """è´¦æˆ·ä½™é¢å“åº”"""
    balance: float
    currency: str = "USD"


class CharacterReferenceRequest(BaseModel):
    """æ–°å¢äººç‰©å›¾åº“è¯·æ±‚"""
    name: str
    image_url: str
    description: str


class CharacterReferenceResponse(BaseModel):
    """äººç‰©å›¾åº“å“åº”"""
    id: str
    name: str
    image_url: str
    description: str
    created_at: str
    updated_at: Optional[str] = None


# ==================== é™æ€æ–‡ä»¶æœåŠ¡ ====================

# æŒ‚è½½å‰ç«¯ç›®å½•
frontend_path = Path(__file__).parent.parent / "frontend"
if frontend_path.exists():
    app.mount("/static", StaticFiles(directory=str(frontend_path)), name="static")


@app.get("/")
async def root():
    """æ ¹è·¯å¾„ - è¿”å›å‰ç«¯é¡µé¢"""
    index_path = frontend_path / "index.html"
    if index_path.exists():
        return FileResponse(str(index_path))
    return {"message": "AI Video Generation API", "docs": "/docs"}


# ==================== API ç«¯ç‚¹ ====================

@app.on_event("startup")
async def on_startup_event():
    """æœåŠ¡å¯åŠ¨æ—¶å…ˆå°è¯•ä¿®å¤ä»»åŠ¡çŠ¶æ€"""
    reconcile_task_states()
    bootstrap_eta_history()


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "timestamp": datetime.now().isoformat(),
        "running_tasks": len(running_tasks),
        "max_concurrent": MAX_CONCURRENT_TASKS
    }


@app.get("/api/character-references", response_model=List[CharacterReferenceResponse])
async def list_character_references_endpoint():
    """è¿”å›å·²ä¿å­˜çš„äººç‰©å‚è€ƒå›¾åº“ã€‚"""
    return character_library.list_references()


@app.post("/api/character-references", response_model=CharacterReferenceResponse)
async def create_character_reference_endpoint(request: CharacterReferenceRequest):
    """éªŒè¯å¹¶ä¿å­˜æ–°çš„å‚è€ƒäººç‰©å›¾ã€‚"""
    validate_character_image_url(request.image_url.strip())
    try:
        record = character_library.upsert_reference(
            name=request.name,
            image_url=request.image_url,
            description=request.description
        )
    except ValueError as exc:
        raise HTTPException(status_code=400, detail=str(exc)) from exc
    return record


@app.post("/api/jobs", response_model=JobResponse)
async def create_job(request: JobCreateRequest, background_tasks: BackgroundTasks):
    """
    åˆ›å»ºæ–°çš„è§†é¢‘ç”Ÿæˆä»»åŠ¡

    **åŸºç¡€é…ç½®ï¼š**
    - **topic**: è§†é¢‘ä¸»é¢˜ï¼ˆæ–‡å­—æè¿°ï¼‰
    - **preset_name**: é¢„è®¾é£æ ¼ï¼ˆç§‘æŠ€/å¡é€š/æ—¶å°š/ä»™ä¾ /3D/ç”µå½±/èµ›åšæœ‹å…‹/å¤ªç©º/æˆ·å¤–/é­”æ³•ï¼‰
    - **num_shots**: é•œå¤´æ•°ï¼ˆ1-10ï¼‰
    - **shot_duration**: æ¯é•œå¤´æ—¶é•¿ï¼ˆ3-10ç§’ï¼‰
    - **resolution**: åˆ†è¾¨ç‡ï¼ˆ480p/720p/1080pï¼‰

    **æ¨¡å‹é€‰æ‹©ï¼š**
    - **llm_provider**: LLMæä¾›å•†ï¼ˆä»…æ”¯æŒ 1=DeepSeekï¼‰
    - **image_model**: å›¾åƒæ¨¡å‹ï¼ˆ1-6ï¼‰
    - **video_model**: è§†é¢‘æ¨¡å‹ï¼ˆ1-5ï¼‰
    - **voice**: é…éŸ³éŸ³è‰²ï¼ˆ1-13ï¼‰

    **å·¥ä½œæµé…ç½®ï¼š**
    - **concurrent_workers**: å¹¶å‘çº¿ç¨‹æ•°ï¼ˆ1-9ï¼‰

    **é«˜çº§æ¨¡å¼ï¼š**
    - **user_yaml**: ç”¨æˆ·è‡ªå®šä¹‰ YAML é…ç½®ï¼ˆå®Œæ•´è¦†ç›–ä¸Šè¿°é€‰é¡¹ï¼‰
    """
    try:
        resume_mode = bool(request.resume_id)
        job_id = None
        config_file = None
        config_data = None

        if resume_mode:
            job_id = request.resume_id.strip()
            if not job_id:
                raise HTTPException(status_code=400, detail="æ— æ•ˆçš„ resume_id")

            task = task_manager.get_task(job_id)
            if not task:
                raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {job_id}")

            if task['status'] == 'running':
                raise HTTPException(status_code=400, detail="ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­ï¼Œæ— æ³•ç»§ç»­æ“ä½œ")

            if task['status'] not in ['failed', 'succeeded', 'queued']:
                raise HTTPException(status_code=400, detail=f"å½“å‰çŠ¶æ€ {task['status']} æš‚ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ")

            config_file = Path(TEMP_DIR) / f"user-{job_id}.yaml"
            if not config_file.exists():
                raise HTTPException(status_code=400, detail="æ‰¾ä¸åˆ°ä»»åŠ¡é…ç½®æ–‡ä»¶ï¼Œæ— æ³•æ–­ç‚¹ç»­ä¼ ")

            if request.wavespeed_api_key:
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        resume_config = yaml.safe_load(f) or {}
                except Exception:
                    resume_config = {}

                if not isinstance(resume_config, dict):
                    resume_config = {}

                api_settings = resume_config.get('api') or {}
                api_settings['wavespeed_key'] = request.wavespeed_api_key.strip()
                resume_config['api'] = api_settings

                with open(config_file, 'w', encoding='utf-8') as f:
                    yaml.dump(resume_config, f, allow_unicode=True, default_flow_style=False)
                config_data = resume_config
            else:
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        config_data = yaml.safe_load(f)
                except Exception:
                    config_data = None

            task_manager.update_status(job_id, 'queued', 'é‡æ–°å¼€å§‹ä»»åŠ¡ï¼Œå‡†å¤‡æ–­ç‚¹ç»­ä¼ ')
            task_manager.update_progress(job_id, 0.0, 'é‡æ–°å¼€å§‹ä»»åŠ¡ï¼Œå‡†å¤‡æ–­ç‚¹ç»­ä¼ ')
        else:
            # åˆ›å»ºä»»åŠ¡
            job_id = task_manager.create_task(
                preset_name=request.preset_name,
                num_shots=request.num_shots or 5,
                resolution=request.resolution or "720p",
                user_yaml=request.user_yaml,
                resume_id=request.resume_id,
                no_auto_resume=request.no_auto_resume or False
            )

            # ç”Ÿæˆé…ç½®æ–‡ä»¶
            config_file = Path(TEMP_DIR) / f"user-{job_id}.yaml"
            if request.user_yaml:
                # ä½¿ç”¨ç”¨æˆ·æä¾›çš„ YAML
                with open(config_file, 'w', encoding='utf-8') as f:
                    f.write(request.user_yaml)

                # éªŒè¯ç”¨æˆ·æä¾›çš„é…ç½®
                try:
                    config_data = yaml.safe_load(request.user_yaml)
                    validate_config(config_data)
                except Exception as e:
                    raise HTTPException(status_code=400, detail=f"é…ç½®éªŒè¯å¤±è´¥: {str(e)}")
            else:
                # ä½¿ç”¨æ–°çš„é…ç½®ç”Ÿæˆå‡½æ•°
                config = generate_config_from_preset(
                    topic=request.topic,
                    preset_name=request.preset_name,
                    num_shots=request.num_shots or 5,
                    shot_duration=request.shot_duration or 5,
                    resolution=request.resolution or "720p",
                    llm_provider=request.llm_provider or 1,
                    image_model=request.image_model or 4,
                    video_model=request.video_model or 1,
                    voice=request.voice or 6,
                    concurrent_workers=request.concurrent_workers or 6,
                    job_id=job_id,
                    character_enabled=bool(request.character_enabled),
                    character_image_url=request.character_image_url,
                    character_description=request.character_description,
                    character_name=request.character_name,
                    logo_outro_enabled=request.logo_outro_enabled if request.logo_outro_enabled is not None else True
                )

                # å¦‚æœæä¾›äº†Wavespeed APIå¯†é’¥ï¼Œæ·»åŠ åˆ°é…ç½®ä¸­
                if request.wavespeed_api_key:
                    if 'api' not in config:
                        config['api'] = {}
                    config['api']['wavespeed_key'] = request.wavespeed_api_key.strip()

                # éªŒè¯é…ç½®
                validate_config(config)

                # å†™å…¥æ–‡ä»¶
                with open(config_file, 'w', encoding='utf-8') as f:
                    yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
                config_data = config

        # æ·»åŠ åå°ä»»åŠ¡æ‰§è¡Œ
        background_tasks.add_task(run_video_generation, job_id, config_file, resume_mode)

        # è®¡ç®—å¹¶ä¿å­˜ ETA ä¼°è®¡
        if config_data and not isinstance(config_data, str):
            eta_profile = eta_estimator.estimate(config_data)
            task_manager.set_eta_profile(job_id, eta_profile)
        elif resume_mode and config_data is None:
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    resume_conf = yaml.safe_load(f)
            except Exception:
                resume_conf = None
            if resume_conf:
                eta_profile = eta_estimator.estimate(resume_conf)
                task_manager.set_eta_profile(job_id, eta_profile)

        # è¿”å›ä»»åŠ¡ä¿¡æ¯
        task = task_manager.get_task(job_id)
        return JobResponse(**task)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}")


@app.get("/api/jobs", response_model=dict)
async def list_jobs():
    """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡"""
    reconcile_task_states()
    tasks = task_manager.list_tasks()
    return {
        "jobs": tasks,
        "total": len(tasks)
    }


@app.post("/api/wavespeed/balance", response_model=BalanceResponse)
async def get_wavespeed_balance_api(request: BalanceRequest):
    """æŸ¥è¯¢ Wavespeed API è´¦æˆ·ä½™é¢"""
    api_key = (request.wavespeed_api_key or "").strip()
    if not api_key:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘ Wavespeed API å¯†é’¥")

    try:
        balance = fetch_wavespeed_balance(api_key)
    except requests.exceptions.HTTPError as exc:
        status_code = exc.response.status_code if exc.response else 502
        if status_code == 401:
            raise HTTPException(status_code=401, detail="Wavespeed API å¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ") from exc
        raise HTTPException(status_code=status_code, detail="Wavespeed ä½™é¢æŸ¥è¯¢å¤±è´¥") from exc
    except requests.exceptions.Timeout as exc:
        raise HTTPException(status_code=504, detail="æŸ¥è¯¢ Wavespeed ä½™é¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•") from exc
    except requests.exceptions.RequestException as exc:
        raise HTTPException(status_code=502, detail="æ— æ³•è¿æ¥ Wavespeed æœåŠ¡ï¼Œè¯·ç¨åå†è¯•") from exc

    if balance is None:
        raise HTTPException(status_code=502, detail="æœªèƒ½ä» Wavespeed API è·å–ä½™é¢ä¿¡æ¯")

    return BalanceResponse(balance=round(balance, 2))


@app.get("/api/jobs/{job_id}", response_model=JobResponse)
async def get_job_status(job_id: str):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    reconcile_task_states()
    task = task_manager.get_task(job_id)

    if not task:
        raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {job_id}")

    return JobResponse(**task)


@app.get("/api/jobs/{job_id}/log", response_model=LogResponse)
async def get_job_log(job_id: str, lines: int = 100, offset: int = 0):
    """
    è·å–ä»»åŠ¡æ—¥å¿—

    - **lines**: è¿”å›çš„è¡Œæ•°ï¼ˆé»˜è®¤ 100ï¼‰
    - **offset**: èµ·å§‹è¡Œåç§»ï¼ˆé»˜è®¤ 0ï¼‰
    """
    task = task_manager.get_task(job_id)

    if not task:
        raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {job_id}")

    log_file = Path(OUTPUT_DIR) / job_id / "log.txt"

    if not log_file.exists():
        return LogResponse(lines=[], total_lines=0, eof=True)

    try:
        with open(log_file, 'r', encoding='utf-8', errors='replace') as f:
            all_lines = f.readlines()

        total = len(all_lines)
        start = offset
        end = min(offset + lines, total)

        # ç§»é™¤è¡Œå°¾æ¢è¡Œç¬¦
        selected_lines = [line.rstrip('\n') for line in all_lines[start:end]]

        return LogResponse(
            lines=selected_lines,
            total_lines=total,
            eof=(end >= total)
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è¯»å–æ—¥å¿—å¤±è´¥: {str(e)}")


@app.get("/api/jobs/{job_id}/result")
async def get_job_result(job_id: str):
    """è·å–ä»»åŠ¡ç»“æœ"""
    reconcile_task_states()
    task = task_manager.get_task(job_id)

    if not task:
        raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {job_id}")

    if task['status'] != 'succeeded':
        raise HTTPException(status_code=400, detail=f"ä»»åŠ¡æœªå®Œæˆ: {task['status']}")

    return {
        "job_id": job_id,
        "result_path": task.get('result_path'),
        "status": task['status']
    }


# ==================== è¿›åº¦è¿½è¸ªè¾…åŠ©å‡½æ•° ====================

def parse_checkpoint_file(checkpoint_file: Path) -> Optional[dict]:
    """
    è§£æcheckpointæ–‡ä»¶

    Args:
        checkpoint_file: checkpointæ–‡ä»¶è·¯å¾„

    Returns:
        checkpointå­—å…¸ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æŸååˆ™è¿”å›None
    """
    import json as json_module

    if not checkpoint_file.exists():
        return None

    try:
        with open(checkpoint_file, 'r', encoding='utf-8') as f:
            return json_module.load(f)
    except (json_module.JSONDecodeError, IOError):
        return None


def calculate_progress_from_checkpoint(checkpoint: dict, detailed: bool = False) -> float:
    """
    æ ¹æ®checkpointè®¡ç®—è¿›åº¦ï¼ŒæŒ‰ç…§â€œèµ„äº§â†’å‰§æœ¬â†’å›¾åƒâ†’è§†é¢‘â†’éŸ³é¢‘/åˆæˆâ€æƒé‡æ˜ å°„

    Args:
        checkpoint: checkpointå­—å…¸
        detailed: æ˜¯å¦ä½¿ç”¨è¯¦ç»†è¿›åº¦ï¼ˆè€ƒè™‘å­ä»»åŠ¡ï¼‰

    Returns:
        è¿›åº¦å€¼ (0.0 - 1.0)
    """
    if not checkpoint or 'completed_steps' not in checkpoint:
        return 0.0

    # é˜¶æ®µæƒé‡ï¼ˆç´¯è®¡åä¸º100%ï¼‰
    stage_weights = {
        'assets': 0.10,
        'story': 0.10,
        'images': 0.30,
        'videos': 0.40,
        'audio_subtitle': 0.05,
        'composition': 0.05,
    }

    completed_steps = checkpoint.get('completed_steps', [])
    stages_info = checkpoint.get('stages', {})

    # åªè®¡æ•°å·²çŸ¥æ­¥éª¤ï¼Œä¿æŒé¡ºåº
    valid_completed = []
    seen = set()
    for step in completed_steps:
        if step in stage_weights and step not in seen:
            valid_completed.append(step)
            seen.add(step)

    base_progress = sum(stage_weights[step] for step in valid_completed)

    # å…¼å®¹æ—§checkpointï¼šcharacter_referenceå®Œæˆè§†ä¸ºèµ„äº§é˜¶æ®µå®Œæˆ
    if 'assets' not in seen and stages_info and stages_info.get('character_reference'):
        base_progress += stage_weights.get('assets', 0.0)

    base_progress = min(base_progress, 1.0)

    if not detailed:
        return base_progress

    sub_progress = 0.0

    # å›¾åƒç”Ÿæˆç»†åŒ–
    if 'images' in checkpoint and 'images' not in seen:
        images_info = checkpoint['images']
        if 'completed' in images_info and 'total' in images_info:
            total = images_info['total']
            if total > 0:
                sub_progress = stage_weights['images'] * (images_info['completed'] / total)

    # è§†é¢‘ç”Ÿæˆç»†åŒ–ï¼ˆä»…åœ¨å›¾åƒé˜¶æ®µå®Œæˆä½†è§†é¢‘æœªå®Œæˆæ—¶ï¼‰
    elif 'videos' in checkpoint and 'videos' not in seen:
        videos_info = checkpoint['videos']
        if 'completed' in videos_info and 'total' in videos_info:
            total = videos_info['total']
            if total > 0:
                sub_progress = stage_weights['videos'] * (videos_info['completed'] / total)

    return min(base_progress + sub_progress, 1.0)


def generate_progress_message(checkpoint: dict) -> str:
    """
    æ ¹æ®checkpointç”Ÿæˆè¿›åº¦æ¶ˆæ¯ï¼ˆ5ä¸ªé˜¶æ®µï¼‰

    Args:
        checkpoint: checkpointå­—å…¸

    Returns:
        è¿›åº¦æ¶ˆæ¯å­—ç¬¦ä¸²
    """
    if not checkpoint or 'completed_steps' not in checkpoint:
        return 'å‡†å¤‡ä¸­...'

    completed = checkpoint.get('completed_steps', [])
    stages = checkpoint.get('stages', {})

    # åˆ¤æ–­å½“å‰é˜¶æ®µï¼ˆæŒ‰å€’åºæ£€æŸ¥ï¼‰
    if 'composition' in completed:
        return 'âœ… è§†é¢‘æˆç‰‡å·²å®Œæˆ'
    elif 'audio_subtitle' in completed:
        return 'ğŸ¬ æ­£åœ¨è¿›è¡ŒéŸ³é¢‘ä¸åˆæˆ'
    elif 'videos' in completed:
        return 'ğŸ§ æ­£åœ¨åˆ¶ä½œæ—ç™½ä¸å­—å¹•...'
    elif 'images' in completed:
        videos_info = checkpoint.get('videos', {})
        if 'completed' in videos_info and 'total' in videos_info:
            c = videos_info['completed']
            t = videos_info['total']
            return f'ğŸ¥ æ­£åœ¨ç”Ÿæˆè§†é¢‘ ({c}/{t})'
        return 'âœ… å›¾åƒç”Ÿæˆå®Œæˆï¼Œå‡†å¤‡ç”Ÿæˆè§†é¢‘'
    elif 'story' in completed:
        images_info = checkpoint.get('images', {})
        if 'completed' in images_info and 'total' in images_info:
            c = images_info['completed']
            t = images_info['total']
            return f'ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆå›¾åƒ ({c}/{t})'
        return 'âœ… å‰§æœ¬ç”Ÿæˆå®Œæˆï¼Œå‡†å¤‡ç”Ÿæˆå›¾åƒ'
    elif 'assets' in completed or stages.get('character_reference'):
        return 'ğŸ§¬ æ­£åœ¨å‡†å¤‡è§’è‰²ä¸å“ç‰Œèµ„äº§...'
    else:
        return 'ğŸš€ æ­£åœ¨åˆå§‹åŒ–ä»»åŠ¡...'


# ==================== ç»“æœæ•´ç†ä¸çŠ¶æ€ä¿®å¤ ====================

def locate_final_video(output_dir: Path) -> Optional[Path]:
    """åœ¨è¾“å‡ºç›®å½•ä¸­å¯»æ‰¾æœ€ç»ˆè§†é¢‘æ–‡ä»¶"""
    preferred_paths = [
        output_dir / 'final_video.mp4',
        output_dir / 'final.mp4',
        output_dir / '90_final.mp4',
    ]
    for candidate in preferred_paths:
        if candidate.exists():
            return candidate

    final_candidates = sorted(output_dir.glob("*final*.mp4"))
    if final_candidates:
        return final_candidates[-1]
    return None


def prepare_final_result(job_id: str) -> Optional[str]:
    """
    æŸ¥æ‰¾å¹¶æ•´ç†æœ€ç»ˆè§†é¢‘æ–‡ä»¶ï¼Œè¿”å›å¯ä¾›å‰ç«¯è®¿é—®çš„è·¯å¾„
    """
    output_dir = Path(OUTPUT_DIR) / job_id
    if not output_dir.exists():
        return None

    result_file = locate_final_video(output_dir)
    if not result_file:
        return None

    final_name = f"{job_id}.mp4"
    canonical_path = output_dir / final_name

    try:
        if not canonical_path.exists() or result_file.resolve() != canonical_path.resolve():
            shutil.copy2(result_file, canonical_path)
    except Exception as copy_err:
        print(f"[WARN] æ— æ³•ç”Ÿæˆå‘½åæ–‡ä»¶ {canonical_path}: {copy_err}")
        canonical_path = result_file

    public_url = None
    if canonical_path.exists():
        try:
            PUBLIC_EXPORT_DIR.mkdir(parents=True, exist_ok=True)
            public_target = PUBLIC_EXPORT_DIR / final_name
            need_copy = True
            if public_target.exists():
                need_copy = canonical_path.stat().st_mtime > public_target.stat().st_mtime
            if need_copy:
                shutil.copy2(canonical_path, public_target)
            public_url = f"{PUBLIC_EXPORT_URL.rstrip('/')}/{final_name}"
        except Exception as export_err:
            print(f"[WARN] æ— æ³•å¤åˆ¶è§†é¢‘åˆ°å…¬å…±å­˜å‚¨ {PUBLIC_EXPORT_DIR}: {export_err}")
            public_url = str(canonical_path)

    if public_url:
        return public_url
    if canonical_path.exists():
        return str(canonical_path)
    return str(result_file)


def reconcile_task_states():
    """
    æ‰«æä»»åŠ¡åˆ—è¡¨ï¼Œä¿®å¤å·²å®Œæˆä½†çŠ¶æ€æœªæ›´æ–°çš„ä»»åŠ¡
    """
    tasks_snapshot = task_manager.list_tasks()
    for task in tasks_snapshot:
        job_id = task.get('job_id')
        if not job_id:
            continue

        status = task.get('status')
        result_path = task.get('result_path')

        if status == 'succeeded' and result_path:
            continue

        final_result = prepare_final_result(job_id)
        if not final_result:
            continue

        task_manager.set_result_path(job_id, final_result)
        if status != 'succeeded':
            task_manager.update_status(job_id, 'succeeded', 'è§†é¢‘ç”ŸæˆæˆåŠŸï¼ˆçŠ¶æ€è‡ªåŠ¨ä¿®å¤ï¼‰')
            task_manager.update_progress(job_id, 1.0, 'å·²å®Œæˆ')


def bootstrap_eta_history():
    """åŸºäºå†å²æˆåŠŸä»»åŠ¡æ„å»º ETA æ ·æœ¬"""
    global eta_bootstrap_done
    if eta_bootstrap_done:
        return

    try:
        tasks = task_manager.list_tasks()
        tasks_sorted = sorted(
            [task for task in tasks if task.get('status') == 'succeeded'],
            key=lambda item: item.get('created_at', '')
        )
        imported = 0
        for task in tasks_sorted:
            job_id = task.get('job_id')
            if not job_id or eta_estimator.has_record(job_id):
                continue
            config_path = Path(TEMP_DIR) / f"user-{job_id}.yaml"
            log_path = Path(OUTPUT_DIR) / job_id / "log.txt"
            if not config_path.exists() or not log_path.exists():
                continue
            if eta_estimator.record_success(job_id, config_path, log_path):
                imported += 1
        if imported:
            print(f"[INFO] å·²å¯¼å…¥ {imported} ä¸ªå†å² ETA æ ·æœ¬")
    except Exception as exc:
        print(f"[WARN] å¯¼å…¥å†å² ETA æ ·æœ¬å¤±è´¥: {exc}")
    finally:
        eta_bootstrap_done = True


# ==================== åå°ä»»åŠ¡æ‰§è¡Œ ====================

async def run_video_generation(job_id: str, config_file: Path, resume_mode: bool = False):
    """
    åå°è¿è¡Œè§†é¢‘ç”Ÿæˆä»»åŠ¡

    Args:
        job_id: ä»»åŠ¡ ID
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
    """
    global running_tasks

    # æ£€æŸ¥å¹¶å‘é™åˆ¶
    while len(running_tasks) >= MAX_CONCURRENT_TASKS:
        await asyncio.sleep(1)

    try:
        # æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­ï¼ˆé¦–é˜¶æ®µæ˜¯æ•…äº‹è„šæœ¬ç”Ÿæˆï¼‰
        task_manager.update_status(job_id, 'running', 'æ­£åœ¨ç”Ÿæˆæ•…äº‹è„šæœ¬...')

        # æ„å»ºå‘½ä»¤
        ad_back_path = Path(__file__).parent / 'ad-back.py'
        log_file = Path(OUTPUT_DIR) / job_id / 'log.txt'

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        log_file.parent.mkdir(parents=True, exist_ok=True)

        cmd = [
            sys.executable,  # ä½¿ç”¨å½“å‰ Python è§£é‡Šå™¨
            str(ad_back_path),
            '--resume', job_id,
            '--config-file', str(config_file),
            '--no-auto-resume'
        ]

        # å¯åŠ¨å­è¿›ç¨‹
        append_existing_log = resume_mode and log_file.exists()
        mode = 'a' if append_existing_log else 'w'
        with open(log_file, mode, encoding='utf-8') as log_f:
            if append_existing_log:
                separator = "=" * 20
                log_f.write(f"\n{separator} æ–­ç‚¹ç»­ä¼ å¯åŠ¨ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} {separator}\n")
                log_f.flush()
            process = subprocess.Popen(
                cmd,
                stdout=log_f,
                stderr=subprocess.STDOUT,
                cwd=Path(__file__).parent.parent,  # é¡¹ç›®æ ¹ç›®å½•
                env=os.environ.copy()
            )

        running_tasks[job_id] = process

        # å¼‚æ­¥è½®è¯¢ï¼šç›‘æ§è¿›åº¦å¹¶ç­‰å¾…å®Œæˆ
        checkpoint_file = Path(OUTPUT_DIR) / job_id / '00_checkpoint.json'
        last_progress = 0.0

        while process.poll() is None:
            # è§£æcheckpointæ–‡ä»¶
            checkpoint = parse_checkpoint_file(checkpoint_file)

            if checkpoint:
                # è®¡ç®—è¿›åº¦
                progress = calculate_progress_from_checkpoint(checkpoint, detailed=True)
                message = generate_progress_message(checkpoint)

                # åªåœ¨è¿›åº¦å˜åŒ–æ—¶æ›´æ–°ï¼ˆé¿å…é¢‘ç¹å†™å…¥ï¼‰
                if abs(progress - last_progress) >= 0.01:  # å˜åŒ–è¶…è¿‡1%æ‰æ›´æ–°
                    task_manager.update_progress(job_id, progress, message)
                    last_progress = progress

            # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
            await asyncio.sleep(PROGRESS_POLL_INTERVAL)

        # è·å–é€€å‡ºç 
        returncode = process.returncode

        # ç§»é™¤è¿è¡Œè®°å½•
        if job_id in running_tasks:
            del running_tasks[job_id]

        # æ›´æ–°çŠ¶æ€
        if returncode == 0:
            # æŸ¥æ‰¾ç”Ÿæˆçš„è§†é¢‘æ–‡ä»¶
            final_result = prepare_final_result(job_id)
            if final_result:
                task_manager.set_result_path(job_id, final_result)
                task_manager.update_status(job_id, 'succeeded', 'è§†é¢‘ç”ŸæˆæˆåŠŸ')
                task_manager.update_progress(job_id, 1.0, 'å·²å®Œæˆ')
                try:
                    eta_estimator.record_success(job_id, config_file, log_file)
                except Exception as eta_err:
                    print(f"[WARN] è®°å½• ETA æ•°æ®å¤±è´¥: {eta_err}")
            else:
                task_manager.update_status(job_id, 'failed', 'æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶')
        else:
            task_manager.update_status(job_id, 'failed', f'ç”Ÿæˆå¤±è´¥ï¼Œé€€å‡ºç : {returncode}')

    except Exception as e:
        # å¼‚å¸¸å¤„ç†
        task_manager.update_status(job_id, 'failed', f'æ‰§è¡Œå¼‚å¸¸: {str(e)}')

        if job_id in running_tasks:
            del running_tasks[job_id]


# ==================== å¯åŠ¨å…¥å£ ====================

if __name__ == "__main__":
    import uvicorn

    print("ğŸš€ å¯åŠ¨ API æœåŠ¡...")
    print(f"   - Swagger æ–‡æ¡£: http://localhost:18000/docs")
    print(f"   - å¥åº·æ£€æŸ¥: http://localhost:18000/health")
    print()

    uvicorn.run(app, host="0.0.0.0", port=18000)
